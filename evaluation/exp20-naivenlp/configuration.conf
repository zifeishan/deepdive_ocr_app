deepdive {

  db.default: {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    # " (fix highlighting)
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  schema.variables {
    # labels
    candidate.label: Boolean
  }

  extraction.extractors: {

    # K-fold a fraction of documents.
    ext_no_holdout {
      input: "select * from document"
      output_relation: "document"
      udf: "true"  # Do-nothing extractor
      before: ${APP_HOME}"/udf/before_ext_fold.sh"
    }
    # K-fold a fraction of documents.
    ext_holdout_document {
      input: "select * from document"
      output_relation: "document"
      udf: "true"
      before: ${APP_HOME}"/udf/before_ext_fold.sh"
      after: ${APP_HOME}"/udf/kfold.py "${KFOLD_NUM}" "${KFOLD_ITER}" document docid"
      # udf: "/bin/cat"
    }

    # Extract naive ocr-specific features
    ext_naivefeature {
      input: """
        SELECT id, word, source
          from cand_word
        """
        # TOO SLOW: NO CURSER
      # input: "SELECT * from candidate"

      # input: "SELECT * from candidate where docid = 'JOURNAL_102371'"
      output_relation: "feature"
      before: ${APP_HOME}"/udf/before_naivefeature.sh"
      udf: "pypy "${APP_HOME}"/udf/ext_naivefeature.py"
      parallelism: ${MAX_PARALLELISM}
      # input_batch_size: 5000
      # output_batch_size: 5000
    }

    ext_sup_1gram {
      dependencies: ["ext_holdout_document", "ext_no_holdout"]
      # Document table is already held out
      input: "select * from document"
      output_relation: "document"
      udf: "true"
      before: ${APP_HOME}"/udf/before_cand_label.sh"
      # udf: "pypy "${APP_HOME}"/udf/ext_cand_label.py"
      after: ${APP_HOME}"/udf/after_cand_label_sup1gram.sh"
    }
    # DO NOT HAVE DATA FOR JOURNAL_107511

    # ext_sup_1gram_2gram {
    #   dependencies: ["ext_holdout_document", "ext_no_holdout"]
    #   # input: "SELECT id from candidate"
    #   # Document table is already held out
    #   input: """
    #   SELECT id as "candidate.id" 
    #   from candidate"""
    #   output_relation: "cand_label"
    #   before: ${APP_HOME}"/udf/before_cand_label.sh"
    #   # udf: "pypy "${APP_HOME}"/udf/ext_cand_label.py"
    #   udf: "true"
    #   after: ${APP_HOME}"/udf/after_cand_label_sup1gram_2gram.sh"
    # }

    # array_agg(id order by varid, candid, wordid) as arr_id,
    # array_agg(candid order by varid, candid, wordid) as arr_candid,
    # array_agg(wordid order by varid, candid, wordid) as arr_wordid,
    ext_sup_orderaware {
      dependencies: ["ext_holdout_document", "ext_no_holdout"]
      input: """select 
        docid,
        array_agg(candidate_id order by varid, candid, wordid) as arr_candidate_id,
        array_agg(varid order by varid, candid, wordid) as arr_varid,
        array_agg(word order by varid, candid, wordid) as arr_word
        from cand_word
        group by docid
        """
      # where docid in (select * from eval_docs)
      output_relation: "orderaware_supv_label"
      udf: "pypy "${APP_HOME}"/udf/ext_sup_orderaware.py"
      parallelism: ${MAX_PARALLELISM}
      before: ${APP_HOME}"/udf/before_sup_orderaware.sh"
      after: ${APP_HOME}"/udf/after_sup_orderaware.sh"
      input_batch_size: 1
    }

    ext_sup_holdout_labels {
      dependencies: ["ext_sup_1gram", "ext_sup_1gram_2gram", "ext_sup_orderaware"]
      input: """select * from document limit 1"""
      output_relation: "document"
      udf: "true"
      after: ${APP_HOME}"/udf/after_sup_holdout_labels.sh"

    }

    # ext_f_ngram {
    #   # TODO write a general script to lable sequences with ngram!!
    # }
  }

  inference.factors: {

    ########## NEW FORMAT FOR INFERENCE RULES #########
    # Weight column
    # ID for each variables
    # label (var) column
    # naming convention: select id from 

    f_naivefeature {
      input_query: """
        select
          feature.fname as "feature.fname", 
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from feature, candidate, cand_word
        where feature.cand_word_id = cand_word.id
          and cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(candidate.label)"
      weight: "?(feature.fname)"
    }

    f_nlp_pos {
      input_query: """
        select pos as "cand_word.pos",
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from cand_word, candidate
        where cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(candidate.label)"
      weight: "?(cand_word.pos)"
    }

# TODO
    # f_nlp_pos_2gram {
    # }

    f_nlp_ner {
      input_query: """
        select pos as "cand_word.ner",
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from cand_word, candidate
        where cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(candidate.label)"
      weight: "?(cand_word.ner)"
    }

    f_ocr_bias {
      input_query: """
        select 
          candidate.source as "candidate.source",
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from candidate
        """
      function: "IsTrue(candidate.label)"
      weight: "?(candidate.source)"
    }

    # f_nlp_pos {
    #   input_query: """
    #     select 
    #       candidate.source as "candidate.source",
    #       candidate.id as "candidate.id",
    #       candidate.label as "candidate.label"
    #     from candidate
    #     """
    #   function: "IsTrue(candidate.label)"
    #   weight: "?(candidate.source)"
    # }

    f_constraint {
      # Cannot reverse natural join order: id MUST BE cand_label.id!!
      # select c1.id as "candidate.c1.id", 
      #   c2.id as "candidate.c2.id", 

      # ALREADY DISTINCT
      input_query: """
        select 
          c1.id as "candidate.c1.id", 
          c2.id as "candidate.c2.id", 
          c1.label as "candidate.c1.label", 
          c2.label as "candidate.c2.label"
        from candidate as c1, candidate as c2
        where c1.variable_id = c2.variable_id
          and c1.id != c2.id
        """
      # function: "Imply(candidate.c1.label, !candidate.c2.label)"
      # # weight: "?"
      # weight: 30
      function: "And(candidate.c1.label, candidate.c2.label)"
      # weight: "?"
      weight: -20
    }

    # f_agree_bonus {
    #   # Different source, same output: both correct. 
    #     More agree, more correct
    # }

    # Positive: In google ngram
    f_1gram_pos {
      input_query: """
        select 
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        FROM candidate, cand_word
        where cand_word.word in 
        (select gram from ngram_1 where count > 1000)
        and cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(candidate.label)"
      weight: "?"
    }

    # negative: not in google ngram, or too few
    f_1gram_neg {
      input_query: """
        select 
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        FROM candidate, cand_word
        where not exists
        (select * from ngram_1 
          where count > 1000 
          and cand_word.word = gram
          )
        and cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(!candidate.label)"
      weight: "?"
    }
    # # Positive: In google ngram
    # f_2gram_pos {
    #   input_query: """
    #     select
    #       l1.id as "cand_label.l1.id", 
    #       l2.id as "cand_label.l2.id", 
    #       l1.label as "cand_label.l1.label", 
    #       l2.label as "cand_label.l2.label"
    #     from candidate as c1, candidate as c2, 
    #       cand_label as l1, cand_label as l2
    #     where c1.id = l1.candidateid and c2.id = l2.candidateid
    #       and c1.docid = c2.docid 
    #       and c1.wordid = c2.wordid - 1
    #       and c1.word||' '||c2.word in 
    #       (select gram from ngram_2 where count > 100)
    #     """
    #   function: "And(cand_label.l1.label, cand_label.l2.label)"
    #   weight: "?"
    # }
  }

  calibration.holdout_fraction: ${CALI_FRACTION}

  # sampler.sampler_args: "-l 100 -s 10 -i 100 -t 1"

  # Madmax localization
  # inference.batch_size = 100000
  # testing:
  inference.batch_size = 500000
  # sampler.java_args: "-Xmx128g"
  # sampler.sampler_cmd: "/dfs/rulk/0/hazy_share/dw gibbs"
  sampler.sampler_cmd: "util/sampler-dw-linux gibbs"
  # sampler.sampler_args: "-l 150 -s 10 -i 500"
  # sampler.sampler_args: "-l 200 -s 10 -i 500 --alpha 0.0001"
  sampler.sampler_args: "-l 300 -s 1 -i 1000 --alpha 0.01" # Which better?
  # pick a small learning rate to try to learn a correct weight

  pipeline.pipelines.naiveextract: [
    "ext_holdout_document",
    "ext_naivefeature"
    ]

  pipeline.pipelines.noextract: [
    "ext_holdout_document",
    "ext_sup_1gram",
    # "ext_sup_1gram_2gram",
    "ext_sup_holdout_labels",
    "f_naivefeature",
    "f_constraint",
    # "f_agree_bonus",
    "f_ocr_bias",
    # "f_1gram_pos",
    "f_1gram_neg"
    ]
  # pipeline.pipelines.labelonly: ["ext_sup_1gram"]
  pipeline.pipelines.empty: []
  pipeline.pipelines.simple: [
    "ext_holdout_document",
    "ext_sup_1gram",
    "ext_sup_holdout_labels",
    "f_ocr_bias"
  ]

  # NOTICE: cannot use '', must use ""!!

  pipeline.pipelines.sup2gram_nonaive: [
      "ext_holdout_document",
      # "ext_sup_1gram_2gram",
      "ext_sup_holdout_labels",
      "f_constraint",
      # "f_agree_bonus",
      "f_ocr_bias",
      # "f_1gram_pos",
      "f_1gram_neg",
      # "f_2gram_pos"
      ]

  pipeline.pipelines.testcon: [
      "ext_no_holdout",
      # "ext_sup_1gram_SMALLSET",
      "ext_sup_holdout_labels",
      "f_naivefeature",
      "f_constraint",
      # "f_agree_bonus",
      "f_ocr_bias",
      # "f_1gram_pos",
      "f_1gram_neg",
      # "f_2gram_pos"
      ]

  pipeline.pipelines.sup2gram: [
    "ext_holdout_document",
    # "ext_naivefeature",
    # "ext_sup_1gram_2gram",
    "ext_sup_holdout_labels",
    "f_naivefeature",
    "f_ocr_bias",
    "f_constraint",
    # "f_agree_bonus",
    # "f_1gram_pos",
    "f_1gram_neg",
    # "f_2gram_pos"
    ]

  pipeline.pipelines.testorderaware_extract: [
    "ext_naivefeature",
    "ext_holdout_document",
    # "ext_sup_1gram",
    # "ext_sup_1gram_2gram",
    "ext_sup_orderaware",
    "ext_sup_holdout_labels",
    "f_naivefeature",
    "f_constraint",
    # "f_agree_bonus",
    "f_ocr_bias",
    # "f_1gram_pos",
    # "f_1gram_neg"
    ]

  pipeline.pipelines.orderaware: [
    # # "ext_naivefeature",
    # "ext_holdout_document",
    # # "ext_sup_1gram",
    # # "ext_sup_1gram_2gram",
    # "ext_sup_orderaware",
    "ext_sup_holdout_labels",
    "f_naivefeature",
    "f_constraint",
    "f_nlp_pos",
    "f_nlp_ner",
    # "f_agree_bonus",
    "f_ocr_bias",
    "f_1gram_pos",
    "f_1gram_neg"
    ]

  pipeline.pipelines.bestpick: [
    # "ext_naivefeature",
    "ext_no_holdout",
    # "ext_sup_1gram",
    # "ext_sup_1gram_2gram",
    "ext_sup_orderaware",
    "ext_sup_holdout_labels",
    # "f_naivefeature",
    # "f_constraint",
    # "f_agree_bonus",
    # "f_ocr_bias",
    # "f_1gram_pos",
    # "f_1gram_neg"
    ]
  # pipeline.run: "sup2gram"
  # pipeline.run: "empty"
  # pipeline.run: "testcon"
  # pipeline.run: "noextract"
  # pipeline.run: "naiveextract"
  pipeline.run: "orderaware"
  # pipeline.run: "bestpick"


}


# Regex to select all rules:  "    ext|f_.*\{"