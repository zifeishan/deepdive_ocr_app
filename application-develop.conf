deepdive {

  db.default: {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    # " (fix highlighting)
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  schema.variables {
    # labels
    candidate.label: Boolean
  }

  extraction.extractors: {

    # K-fold a fraction of documents.
    ext_no_holdout {
      input: "select * from document limit 0"
      output_relation: "document"
      udf: "true"  # Do-nothing extractor
      before: ${APP_HOME}"/udf/before_ext_fold.sh"
    }
    # K-fold a fraction of documents.
    ext_holdout_document {
      input: "select * from document limit 0"
      output_relation: "document"
      udf: "true"
      before: ${APP_HOME}"/udf/before_ext_fold.sh"
      after: ${APP_HOME}"/udf/kfold.py "${KFOLD_NUM}" "${KFOLD_ITER}" document docid"
      # udf: "/bin/cat"
    }
    # K-fold a fraction of documents.
    ext_holdout_from_orderaware {
      input: "select * from document limit 0"
      output_relation: "document"
      udf: "true"  # Do-nothing extractor
      before: ${APP_HOME}"/udf/before_ext_fold_from_orderaware.sh"
    }

    # Extract naive ocr-specific features
    ext_naivefeature {
      input: """
        SELECT id, word, source
          from cand_word
        """
        # TOO SLOW: NO CURSER
      # input: "SELECT * from candidate"

      # input: "SELECT * from candidate where docid = 'JOURNAL_102371'"
      output_relation: "feature"
      before: ${APP_HOME}"/udf/before_naivefeature.sh"
      udf: "pypy "${APP_HOME}"/udf/ext_naivefeature.py"
      parallelism: ${MAX_PARALLELISM}
      # input_batch_size: 5000
      # output_batch_size: 5000
    }

    ext_sup_1gram {
      dependencies: ["ext_holdout_document", "ext_no_holdout", "ext_holdout_from_orderaware"]
      # Document table is already held out
      input: "select * from document limit 0"
      output_relation: "document"
      udf: "true"
      before: ${APP_HOME}"/udf/before_cand_label.sh"
      # udf: "pypy "${APP_HOME}"/udf/ext_cand_label.py"
      after: ${APP_HOME}"/udf/after_cand_label_sup1gram.sh"
    }
    # DO NOT HAVE DATA FOR JOURNAL_107511

    # ext_sup_1gram_2gram {
    #   dependencies: ["ext_holdout_document", "ext_no_holdout", "ext_holdout_from_orderaware"]
    #   # input: "SELECT id from candidate"
    #   # Document table is already held out
    #   input: """
    #   SELECT id as "candidate.id" 
    #   from candidate"""
    #   output_relation: "cand_label"
    #   before: ${APP_HOME}"/udf/before_cand_label.sh"
    #   # udf: "pypy "${APP_HOME}"/udf/ext_cand_label.py"
    #   udf: "true"
    #   after: ${APP_HOME}"/udf/after_cand_label_sup1gram_2gram.sh"
    # }

    # array_agg(id order by varid, candid, wordid) as arr_id,
    # array_agg(candid order by varid, candid, wordid) as arr_candid,
    # array_agg(wordid order by varid, candid, wordid) as arr_wordid,
    # TAKES VERY LONG
    ext_sup_orderaware {
      dependencies: ["ext_holdout_document", "ext_no_holdout", "ext_holdout_from_orderaware"]
      input: """select 
        docid,
        array_agg(candidate_id order by varid, candid, wordid) as arr_candidate_id,
        array_agg(varid order by varid, candid, wordid) as arr_varid,
        array_agg(word order by varid, candid, wordid) as arr_word
        from cand_word
        group by docid
        """
        # TODO CHECK IT!!
      # where docid in (select * from eval_docs)
      output_relation: "orderaware_supv_label"
      udf: "pypy "${APP_HOME}"/udf/ext_sup_orderaware.py"
      parallelism: ${MAX_PARALLELISM}
      before: ${APP_HOME}"/udf/before_sup_orderaware.sh"
      # after: ${APP_HOME}"/udf/after_sup_orderaware.sh"
      input_batch_size: 1
      output_batch_size: 10000
    }

    ext_sup_orderaware_incremental {
      dependencies: ["ext_holdout_document", "ext_no_holdout", "ext_holdout_from_orderaware"]
      input: """select 
        docid,
        array_agg(candidate_id order by varid, candid, wordid) as arr_candidate_id,
        array_agg(varid order by varid, candid, wordid) as arr_varid,
        array_agg(word order by varid, candid, wordid) as arr_word
        from cand_word
        where not exists
        (select distinct docid from orderaware_supv_label
          where orderaware_supv_label.docid = cand_word.docid
          )
        group by docid
        """
        # TODO CHECK IT!!
      # where docid in (select * from eval_docs)
      output_relation: "orderaware_supv_label"
      udf: "pypy "${APP_HOME}"/udf/ext_sup_orderaware.py"
      parallelism: ${MAX_PARALLELISM}
      # before: ${APP_HOME}"/udf/before_sup_orderaware.sh"
      # after: ${APP_HOME}"/udf/after_sup_orderaware.sh"
      input_batch_size: 1
      output_batch_size: 10000
    }
    # NO EXTRACT, Use only
    ext_sup_use_orderaware {
      dependencies: ["ext_sup_orderaware"],
      input: """select * from document limit 0"""
      output_relation: "document"
      udf: "true"
      before: ${APP_HOME}"/udf/before_cand_label.sh"
      after: ${APP_HOME}"/udf/after_sup_orderaware.sh"

    }

    # Deprecated since DD's manual holdout is enabled
    ext_sup_holdout_labels {
      dependencies: ["ext_sup_1gram", "ext_sup_1gram_2gram", "ext_sup_use_orderaware"]
      input: """select * from document limit 0"""
      output_relation: "document"
      udf: "true"
      after: ${APP_HOME}"/udf/after_sup_holdout_labels.sh"

    }

    # Extract all pairs of possible words that appears in google 2gram.
    ext_cand_2gram {
      input: """select 
        docid,
        array_agg(id order by varid, candid, wordid) as arr_cand_word_id,
        array_agg(candidate_id order by varid, candid, wordid) as arr_candidate_id,
        array_agg(varid order by varid, candid, wordid) as arr_varid,
        array_agg(candid order by varid, candid, wordid) as arr_candid,
        array_agg(word order by varid, candid, wordid) as arr_feature
        from cand_word
        group by docid
        """
      output_relation: "cand_2gram"
      udf: "pypy "${APP_HOME}"/udf/ext_cand_ngram.py 2"
      parallelism: ${MAX_PARALLELISM}
      before: ${APP_HOME}"/udf/before_cand_2gram.sh"
      after: ${APP_HOME}"/udf/after_cand_2gram.sh"
      input_batch_size: 1
    }

    # ext_pos_3gram {
    #   # TODO write a general script to lable sequences with ngram!!
    #   input: """select 
    #     docid,
    #     array_agg(cand_word_id order by varid, candid, wordid) as arr_cand_word_id,
    #     array_agg(candidate_id order by varid, candid, wordid) as arr_candidate_id,
    #     array_agg(varid order by varid, candid, wordid) as arr_varid,
    #     array_agg(candid order by varid, candid, wordid) as arr_candid,
    #     array_agg(pos order by varid, candid, wordid) as arr_feature
    #     from cand_word
    #     group by docid
    #     """
    #   output_relation: "pos_3gram"
    #   udf: "pypy "${APP_HOME}"/udf/ext_cand_ngram.py 3"
    #   parallelism: ${MAX_PARALLELISM}
    #   before: ${APP_HOME}"/udf/before_pos_3gram.sh"
    #   after: ${APP_HOME}"/udf/after_pos_3gram.sh"
    #   input_batch_size: 1
    # }
  }

  inference.factors: {

    ########## NEW FORMAT FOR INFERENCE RULES #########
    # Weight column
    # ID for each variables
    # label (var) column
    # naming convention: select id from 

    f_naivefeature {
      input_query: """
        select
          feature.fname as "feature.fname", 
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from feature, candidate, cand_word
        where feature.cand_word_id = cand_word.id
          and cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(candidate.label)"
      weight: "?(feature.fname)"
    }

    f_nlp_pos {
      input_query: """
        select pos as "cand_word.pos",
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from cand_word, candidate
        where cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(candidate.label)"
      weight: "?(cand_word.pos)"
    }

# TODO
    # f_nlp_pos_2gram {
    # }

    f_nlp_ner {
      input_query: """
        select pos as "cand_word.ner",
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from cand_word, candidate
        where cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(candidate.label)"
      weight: "?(cand_word.ner)"
    }

    f_ocr_bias {
      input_query: """
        select 
          candidate.source as "candidate.source",
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from candidate
        """
      function: "IsTrue(candidate.label)"
      weight: "?(candidate.source)"
    }

    # f_nlp_pos {
    #   input_query: """
    #     select 
    #       candidate.source as "candidate.source",
    #       candidate.id as "candidate.id",
    #       candidate.label as "candidate.label"
    #     from candidate
    #     """
    #   function: "IsTrue(candidate.label)"
    #   weight: "?(candidate.source)"
    # }

    f_constraint {
      # Cannot reverse natural join order: id MUST BE cand_label.id!!
      # select c1.id as "candidate.c1.id", 
      #   c2.id as "candidate.c2.id", 

      # ALREADY DISTINCT
      input_query: """
        select 
          c1.id as "candidate.c1.id", 
          c2.id as "candidate.c2.id", 
          c1.label as "candidate.c1.label", 
          c2.label as "candidate.c2.label"
        from candidate as c1, candidate as c2
        where c1.variable_id = c2.variable_id
          and c1.id != c2.id
        """
      # function: "Imply(candidate.c1.label, !candidate.c2.label)"
      # # weight: "?"
      # weight: 30
      function: "And(candidate.c1.label, candidate.c2.label)"
      # weight: "?"
      weight: -20
    }

    # f_agree_bonus {
    #   # Different source, same output: both correct. 
    #     More agree, more correct
    # }

    # Positive: In google ngram
    f_1gram_pos {
      input_query: """
        select 
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        FROM candidate, cand_word
        where cand_word.word in 
        (select gram from ngram_1 where count > 1000)
        and cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(candidate.label)"
      weight: "?"
    }

    # negative: not in google ngram, or too few
    f_1gram_neg {
      input_query: """
        select 
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        FROM candidate, cand_word
        where not exists
        (select * from ngram_1 
          where count > 1000 
          and cand_word.word = gram
          )
        and cand_word.candidate_id = candidate.id
        """
      function: "IsTrue(!candidate.label)"
      weight: "?"
    }

    ############### 2gram features #################
    f_2gram_allpos {
      input_query: """
        select
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from candidate
        where not exists
        (select * from cand_2gram_someneg_candidates
          where candidate.id = candidate_id)
        """
      function: "IsTrue(candidate.label)"
      weight: "?"
    }
    f_2gram_someneg {
      input_query: """
        select
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from candidate, cand_2gram_someneg_candidates
        where candidate.id = candidate_id
        """
      function: "IsTrue(!candidate.label)"
      weight: "?"
    }
    f_2gram_allneg {
      input_query: """
        select
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from candidate
        where not exists
        (select * from cand_2gram_somepos_candidates
          where candidate.id = candidate_id)
        """
      function: "IsTrue(!candidate.label)"
      weight: "?"
    }
    f_2gram_somepos {
      input_query: """
        select
          candidate.id as "candidate.id",
          candidate.label as "candidate.label"
        from candidate, cand_2gram_somepos_candidates
        where candidate.id = candidate_id
        """
      function: "IsTrue(candidate.label)"
      weight: "?"
    }

  }

  calibration {
    # holdout_fraction: ${CALI_FRACTION}
    holdout_query: "INSERT INTO dd_graph_variables_holdout(variable_id) select id from candidate where docid in (select docid from eval_docs);"
  }

  # sampler.sampler_args: "-l 100 -s 10 -i 100 -t 1"

  # Madmax localization
  # inference.batch_size = 100000
  # testing:
  inference.batch_size = 500000
  # sampler.java_args: "-Xmx128g"
  # sampler.sampler_cmd: "/dfs/rulk/0/hazy_share/dw gibbs"
  sampler.sampler_cmd: "util/sampler-dw-linux gibbs"
  # sampler.sampler_args: "-l 150 -s 10 -i 500"
  # sampler.sampler_args: "-l 200 -s 10 -i 500 --alpha 0.0001"
  # 300
  sampler.sampler_args: "-l 1000 -s 1 -i 1000 --alpha 0.01" # Which better?
  # pick a small learning rate to try to learn a correct weight

  pipeline.pipelines.empty: []

  # NOTICE: cannot use '', must use ""!!
  pipeline.pipelines.extract: [
    "ext_naivefeature",
    "ext_holdout_document",
    # "ext_holdout_from_orderaware",
    # "ext_sup_1gram",
    # "ext_sup_1gram_2gram",
    "ext_sup_orderaware",
    "ext_sup_use_orderaware",
    "ext_sup_holdout_labels",
    "f_naivefeature",
    "f_constraint",
    "f_nlp_pos",
    "f_nlp_ner",
    "f_ocr_bias",
    "f_1gram_pos",
    "f_1gram_neg"
    ]


  pipeline.pipelines.orderaware: [
    # "ext_naivefeature",
    # "ext_holdout_document",
    # "ext_holdout_from_orderaware",
    # "ext_sup_1gram",
    # "ext_sup_1gram_2gram",
    # "ext_sup_orderaware",
    # "ext_sup_use_orderaware",
    # "ext_sup_holdout_labels",
    # "ext_cand_2gram",
    "f_naivefeature",
    "f_constraint",
    "f_nlp_pos",
    "f_nlp_ner",
    "f_ocr_bias",
    "f_1gram_pos",
    "f_1gram_neg",
    "f_2gram_somepos",
    "f_2gram_allneg",
    # "f_2gram_someneg", # same as somepos....
    "f_2gram_allpos"
    ]

  pipeline.pipelines.bestpick: [
    # "ext_naivefeature",
    "ext_no_holdout",
    # "ext_sup_1gram",
    # "ext_sup_1gram_2gram",
    "ext_sup_orderaware",
    "ext_sup_use_orderaware",
    "ext_sup_holdout_labels",
    # "f_naivefeature",
    # "f_constraint",
    # "f_ocr_bias",
    # "f_1gram_pos",
    # "f_1gram_neg"
    ]

  pipeline.pipelines.test2gram: [
    # "ext_naivefeature",
    # "ext_holdout_document",
    # "ext_holdout_from_orderaware",
    # "ext_sup_1gram",
    # "ext_sup_1gram_2gram",
    # "ext_sup_orderaware",
    # "ext_sup_use_orderaware",
    # "ext_sup_holdout_labels",  # deprecated
    "ext_cand_2gram",
    # "f_naivefeature",
    "f_constraint",
    # "f_nlp_pos",
    # "f_nlp_ner",
    "f_ocr_bias",
    # "f_1gram_pos",
    # "f_1gram_neg",
    "f_2gram_somepos",
    "f_2gram_allneg",
    # "f_2gram_someneg", # same as somepos....
    "f_2gram_allpos"
    ]
  # pipeline.run: "sup2gram"
  # pipeline.run: "empty"
  # pipeline.run: "testcon"
  # pipeline.run: "noextract"
  # pipeline.run: "naiveextract"
  pipeline.run: "orderaware" 
  # pipeline.run: "test2gram"

  ### DANGER ZONE
  # pipeline.run: "extract"

  # TODO RUN IT ONCE TO GET ASCII feature
  # pipeline.run: "bestpick"

  inference.skip_learning: true
  # inference.skip_learning: false
  # 


}


# Regex to select all rules:  "    ext|f_.*\{"
