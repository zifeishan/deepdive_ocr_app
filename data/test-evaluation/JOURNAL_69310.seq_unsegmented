Spring predictability barrier of ENSO events from the perspective of an ensemble prediction system Abstract Based on an ENSO (El Niño-Southern Oscillation) ensemble prediction system (EPS), the seasonal variations in the predictability of ENSO are examined in both a deterministic and a probabilistic sense. For the deterministic prediction skills, the skills of the ensemble-mean are sensitive to the month in which the forecast was initiated. The anomaly correlations decrease rapidly during the Northern Hemisphere (NH) spring, and the root mean square (RMS) errors have the largest values and the fastest growth rates initialized before and during the NH spring. However, the probabilistic predictions based on the verification methods of the relative operating character (ROC) curve and area both show that there are no strong seasonal variations for the two extreme (warm and cold) ENSO events. For the near-normal events, the seasonal variations of the probabilistic skills are much more obvious, and the ROC areas of the ensemble forecasts made in the spring are clearly smaller than those of the ensemble forecasts that began during other seasons. At the same time, the probabilistic prediction skills of the EPS for all three events that only consider the initial perturbations are also clearly sensitive to the initial months. This was indicated by the fact that the most rapid decrease of the ROC area skill occurs as the hindcasts proceed through the spring season. A further signal-to-noise ratio analysis reveals that potential sources of the predictability barrier in the probabilistic skills for the EPS are namely that the spring is the period when stochastic initial error effects can be expected to strongly degrade forecast skill, and that small predicted signals can render the system noisier by further limiting the predictability. However, reasonable considerations of the model-error perturbations during the ensemble forecast process can alleviate the barrier caused by initial uncertainties through coordinately simulating the seasonal variations of the forecast uncertainty in order to significantly improve the probabilistic prediction skills and then to disorder the seasonal predictability related to the SPB. Keywords ENSO ; EPS ; SPB 1. Introduction Over the past three decades, ENSO (El Niño-Southern Oscillation) predictions have made remarkable progress, reaching the stage where reasonable predictions can be made 6 to 12 months in advance. However, the “spring predictability barrier” (SPB) is still a problem in many ENSO coupled models and has significant effects in SST (sea surface temperature) predictions ( Jin et al., 2008 ). In particular, the forecast skill of the coupled ocean–atmosphere models depends strongly on the season ( Balmaseda et al., 1995 ). If the predictions have a more obvious decline in skill in the boreal spring than during other seasons, the low predictability is related to the so-called SPB of the ENSO ( Webster and Yang, 1992 ). Recent reviews (e.g., Latif et al., 1998 , Kirtman et al., 2002 and Jin et al., 2008 ) have shown that this strong seasonal variation in the forecast skill is a ubiquitous feature of the current statistical and dynamical prediction models, irrespective of the model's complexity. This seasonality in the forecast skill has been the subject of many studies (e.g., Webster and Yang, 1992 , Xue et al., 1994 , Moore and Kleeman, 1996 , Samelson and Tziperman, 2001 , Chen et al., 2004 , DeWitt, 2005 , Mu et al., 2007a , Mu et al., 2007b , Duan et al., 2009 and Mu et al., submitted for publication ). The cause of the SPB has not yet been fully understood, and various hypotheses have been discussed to explain this phenomenon ( Jin et al., 2008 ). ENSO prediction uncertainties are generally introduced by both the initial errors and the model errors (e.g., Kalnay, 2003 , Zheng et al., 2006 and Leutbecher and Palmer, 2008 ; Zheng and Zhu, 2008 ), and ENSO prediction skills could be significantly influenced by the initial and model errors (e.g., Flügel and Chang, 1998 , Liu, 2002 , Kirtman, 2003 , Garay, 2004 , William, 2005 and Zheng et al., 2009a ). A number of papers have explored the SPB by focusing on the role of initial errors in the SPB. Moore and Kleeman, 1996 and Samelson and Tziperman, 2001 investigated the season-dependent evolutions of initial errors related to the SPB using the linear singular vector approach. Chen et al. (2004) suggested that the ENSO predictability was, to a large degree, limited by the growth of initial errors. Mu et al., 2007a and Mu et al., 2007b used the CNOP (conditional non-linear optimal perturbation) approach and demonstrated that the SPB may be a result of the initial error pattern. Duan et al. (2009) also distinguished the initial errors that cause a significant SPB for El Niño events and emphasized the important effects of initial error CNOP patterns in SPB. These studies all demonstrated that the causation of the SPB might be strongly associated with the growth of the initial errors. There have been few efforts to investigate the impact of the model errors on SPB (e.g., DeWitt, 2005 and Mu et al., submitted for publication ). Dewitt (2005) evaluated the seasonal changes of the probabilistic predictability of a coupled atmosphere–ocean general circulation model (CGCM) using the ROC curve, and showed that the coupled model probabilistic forecast skills were lowest for forecasts during the spring. Mu et al. (submitted for publication) showed that the combined mode of initial error and model parameter error could result in the largest prediction errors and could have potential effects on the significance of an SPB. Since the relationships between the SPB and the model errors have been addressed extensively in the literature, it is unclear whether the initial errors or the model errors are the dominant source of error contributing to a significant SPB. At the same time, the model performance for the ENSO predictability barrier in most of these studies is only verified deterministically. While verifying the models deterministically is useful for examining the model predictability barrier, it is also recognized that ENSO forecasts should be probabilistic (e.g., Palmer, 2000 and Kirtman, 2003 ), and thus that verification must also include a probabilistic assessment of the predictability barrier ( Dewitt, 2005 ). As a result, we need to study and analyze the predictability barrier not only in a deterministic sense, but also in a probabilistic one. In this paper, the predictability barrier of ENSO events is verified from the perspective of a developed ensemble prediction system (EPS; Zheng et al., 2006 and Zheng et al., 2007 ). This EPS can be used to consider both the initial and model errors theoretically and systemically during the prediction process. Thus, the EPS can not only allow us to study the ENSO predictability in a probabilistic sense, but can also provide a platform for attempting to disentangle the impacts of the initial and model uncertainties on ENSO predictability. In this work, a large number of ensemble hindcasts were performed. Each month began with 100 members in the period from November, 1992 to October, 2008, to evaluate the seasonal variations of the EPS predictability. Two additional ensemble hindcast experiments (one considering only the initial uncertainties, another considering only the model uncertainties during the prediction process) were also made to diagnose the potential sources of the predictability barrier by adopting the signal-to-noise ratio analysis approach. The paper is organized as follows. We introduce the EPS in Section 2 . In Section 3 , the seasonality of the prediction skill is verified in both a deterministic and a probabilistic sense. By adopting the signal-to-noise approach, the potential sources causing the prediction barrier in a probabilistic sense are investigated in Section 4 . Finally, we summarize and discuss the results in Section 5 . 2. Description of the ensemble prediction system The EPS consists of three main components. Firstly, the basic model is an ICM developed by Keenlyside and Kleeman, 2002 and Zhang et al., 2003 . Its dynamical component consists of both linear and non-linear components. The former was essentially a McCreary-type (1981) modal model, but was extended to include horizontally-varying background stratification. In addition, ten baroclinic modes, along with a parameterization of local Ekman-driven upwelling, were included. A SST anomaly model was embedded within this dynamical framework to simulate the evolution of the mixed-layer temperature anomalies. As demonstrated by Zhang et al. (2005) , having a realistic parameterization for the temperature of the subsurface water entrained into the mixed-layer ( T e ) is crucial to the performance of SST simulations in the equatorial Pacific. An empirical T e model was constructed from historical data and was demonstrated to be effective in improving the SST simulations. The ocean model was coupled with a statistical atmospheric model, which specifically relates wind stress ( τ ) to SST anomaly fields. All coupled-model components exchange simulated anomaly fields. Information concerning the interactions between the atmosphere ( τ ) and the ocean (SST) was exchanged once a day. Secondly, the initial ensemble conditions of the EPS were provided by the ensemble Kalman filter (EnKF) data assimilation approach ( Evensen, 2003 and Evensen, 2004 ) which assimilates available SST ( Smith and Reynolds, 2004 ) and the TOPEX/Poseidon/Jason-1 (T/P/J) altimeter observations (e.g., Lagerloef et al., 1999 ) into the model with 100 ensemble members ( Zheng and Zhu, 2008 ). This ensemble initialization approach not only generates accurate and dynamically consistent initial fields, but can also provide both reasonable surface and subsurface initial stochastic uncertainties for the EPS by combining both background and observation errors during the assimilation cycles ( Zheng et al., 2007 ). Finally, as described by Zheng et al. (2009b) , a linear, first-order Markov stochastic model was embedded within the SST anomaly model of the ICM. This is required because of the deficiency of simulating the coupled air–sea interactions and subsurface thermal effects in the SST anomaly model and allows the time evolutions of the model uncertainties of forecasted SST anomaly fields to be effectively simulated. This perturbation method was found to be capable of effectively simulating the time evolution of model uncertainties during the ensemble forecasting procedures ( Zheng et al., 2009b ). 3. Seasonality of the prediction skill The retrospective ensemble forecast experiment covering the period between November, 1992 and October, 2008 was compared to available SST observations in order to best evaluate the seasonal variations of the predictability of the EPS in both the deterministic and probabilistic sense ( Smith and Reynolds, 2004 ). A 12-month ensemble hindcast was initialized each month during this 16-year period. For each initial month, an ensemble of 100 hindcasts was run, yielding a total of 19,200 retrospective forecasts to be verified. The seasonal variability of the EPS predictability was evaluated and examined with the help of anomaly correlations and root mean square (RMS) errors for the deterministic skill, and relative operating characteristics (ROC) for the probabilistic skill. However, two issues should be addressed here about the retrospective ensemble forecast experiment. One is that some previous works (e.g., Balmaseda et al., 1995 , Xue et al., 2000 , McPhaden, 2003 and van Oldenborgh et al., 2005 ) have suggested that the inclusion of subsurface information could somewhat alleviate the strong predictability barrier in both statistical and dynamical models. Both SST and T/P/J altimeter data were consistently and dynamically assimilated into the EPS ( Zheng and Zhu, 2008 ) to provide both accurate initial surface and subsurface initial conditions ( Zheng et al., 2007 ) of the hindcast experiment. This allowed us to avoid inadequate verification of the seasonal variations of the predictability due to the deficient initialization of the subsurface information in our retrospective forecast experiment. In addition, the stochastic model-error model was trained for the period 1961–1990 ( Zheng et al., 2006 ). Thus, the hindcast period in this paper does not overlap with the training period, and this treatment also can avoid some of the artificial skills of the EPS. 3.1. Deterministic skill To examine the seasonality of the deterministic skill, anomaly correlations and RMS errors for the ensemble-mean were calculated as a function of the initiation month and the lead time for the entire period. The results of this analysis are compared to the persistence over the Niño 3.4 region in Fig. 1 and Fig. 2 , respectively. As observed in the strong annual cycle of the persistence for the anomaly correlation skill, a striking feature of this analysis was that the deterministic prediction skill in anomaly correlation of SST anomalies depended sensitively on the initiation month, as noted in several previous studies (e.g., Latif et al., 1998 , Xue et al., 2000 and Kirtman et al., 2002 ). The anomaly correlation was relatively low for ensemble-mean predictions beginning in the earlier part of the year before, and even during the spring season and was significantly higher for ensemble-mean predictions starting thereafter. The decay in the anomaly correlation skill for the ensemble-mean forecasts made before and during the spring was much more obvious and rapid than those ensemble-mean forecasts that began after the spring ( Webster and Yang, 1992 and Zhang et al., 2005 ). At the same time, the ensemble-mean forecast was seen to have a higher anomaly correlation coefficient than the persistence for all lead times and initial months. It should also be noted that the decay in the correlation skill for the persistence forecast started before the spring and during the spring was much larger than for the prediction by the ensemble-mean forecasts. As observed in the findings for the anomaly correlation skill and as shown in Fig. 2 , the RMS error skill had a much stronger seasonal variation for persistence forecasts than for the ensemble-mean forecasts. In addition, the RMS errors for both the persistence and the ensemble-mean forecasts had the largest values and the fastest growth rates initialized before and during the spring. Thus, this is another feature of the seasonality of the deterministic skill for the ensemble-mean forecast ( Dewitt, 2005 ). 3.2. Probabilistic skill As described above, the deterministic prediction skill of the EPS clearly shows the presence of an SPB in both the anomaly correlation skill and the RMS error verification. However, aside from simply being the most common means of verifying ENSO forecasts in a deterministic sense, the EPS produces ensemble forecasts that can provide additional useful information. Probabilistic verification is known as an important complement to deterministic verification, which provides a useful and quantitative way to measure uncertainty ( Palmer, 2000 and Kirtman, 2003 ). These additional and supplemental information provided by ensemble forecasts is more useful for evaluating the predictability in a probabilistic sense than the deterministic verifications on their own ( Kalnay, 2003 and DeWitt, 2005 ). Thus, it is also necessary to verify the predictability barrier in a probabilistic sense. To verify the probabilistic skills of the EPS, we have chosen the method commonly referred to as ROC ( Mason, 1982 and Mason and Graham, 1999 ), which measures the ensemble forecast performance by comparing the fraction of events that were forewarned (i.e., the hit rate) with the fraction of non-events that occurred after a warning was issued (i.e., the false alarm rate). The warm events (upper tercile), normal conditions (middle tercile), and cold events (lower tercile) are defined by the probability density distributions of the climatological Niño 3.4 indices from 1971 to 2000. The ROC is an application of signal detection theory on the numerical weather forecast and is used to verify the events predefined and expressed in binary terms. In each model grid, when the two states of the occurrence and nonoccurrence for one event (e.g., warm event) are considered and when the observation is used to verify the forecast, the resultant verification should be one of the following four conditions: the correct forecast (or hit) of the event; the correct rejection of the event; a miss of an event; or a false alarm. Thus, the ROC calculation is based on hit rates and false alarm rates that are calculated from a 2 × 2 contingency table ( Table 1 ). The hit rates ( H ) and the false alarm rates ( F ) are defined by the following equations: equation ( 1 ) Hit Rate ( H ) = A A + C , Turn MathJax on equation ( 2 ) False Alarm Rate ( F ) = B B + D . Turn MathJax on Given an ensemble of hindcasts, an ROC curve can be constructed to show the different combinations of hit and false alarm rates under different forecast probabilities. The ROC curve is useful for identifying optimal strategies for issuing warnings by indicating the trade-off between false alarms and misses. Details and examples of the ROC calculation can be found in Mason and Graham (1999) . Thus, we adopt this ROC method to verify our ensemble hindcast results, which was first introduced into the ENSO ensemble verifications by Kirtman (2003) . For three different events (warm events (upper tercile), near-normal events (middle tercile), and cold events (lower tercile)), the ROC curves computed over the Niño 3.4 region for respective 1-month and 6-month lead forecasts with different initial seasons are shown in Fig. 3 and Fig. 4 . That is, the calculations for consecutive three-month intervals were combined to represent one season. For example, MAM (March–April–May) represents the spring season. By setting the different probability thresholds of the forecast event (from 0 to 100%), the ROC curve can be plotted on the Cartesian coordinates based on the calculated hit rates and false alarm rates. An ideal probabilistic forecast system would have relatively large hit rates and small false alarm rates such that all the points on the ROC curve would cluster in the upper-left corner of the diagram. For a relatively poor forecast system, all the points of the ROC curve would lie very close to the dashed diagonal line indicating that the hit rates and the false alarm rates are nearly the same (i.e., no skill). For the Niño 3.4 region, the ROC curves for three events were all lying to the left of the diagonal line due to their different initial seasons. This indicates that there were obvious probabilistic skills of the EPS for all three different events at both 1- and 6-month lead times. As observed in previous studies (e.g., Kirtman, 2003 , DeWitt, 2005 and Zheng et al., 2009b ), the EPS had a relatively high skill for the warm events and cold events, and a relative low skill for the neutral events. This indicates that the EPS can capture and predict big SST anomaly signals or extreme events over the Niño 3.4 region in different seasons quite well, and the model is apt to predict extreme events ( Chen et al., 2004 ). However, for the three different events, some differences for the seasonal variability in the probabilistic skills can be observed when comparing the ROC skills between 1- and 6-month lead times. For all three events, when a 1-month lead time was used, the ensemble forecasts that were initiated during the SON season showed the largest ROC probabilistic skills, while the ensemble forecasts initiated in the MAM (spring) season had the lowest ROC probabilistic skills. For a 6-month lead time, especially for the warm and cold events, the ensemble forecasts started from the MAM season had the largest ROC probabilistic skills and the ensemble forecasts started during the SON season had the lowest ROC probabilistic skills. The ROC probabilistic skills started during the other two seasons were comparable at either 1- or 6-month lead times. These phenomena indicate that the initial ensemble states have the lowest probabilistic skills when initializing the EPS in spring (MAM) season, and then cause the ensemble forecasts to have relatively poor probabilistic skills at a short lead time. For a longer lead time (e.g., 6-months), when the ensemble forecasts initialized from autumn (SON) season strode through the spring season, the decay of the probabilistic skill of the ensemble forecasts initialized during the autumn season was rapider than those of the ensemble forecasts initiated during other seasons. The dramatic drop in the ROC skills during the spring when the ensemble predictions are made in the spring or when the ensemble predictions include the spring also suggest that the EPS might also address the problem of SPB in a probabilistic sense. The comparisons of the ROC curve starting from different seasons for the specified event cannot clearly distinguish the continuous seasonal variability of the probabilistic skill. Thus, in order to further illustrate the seasonal variations of the ROC probabilistic skill, the ROC area, which is the area under the ROC curve, is calculated by Eq. (3) . An ensemble forecast system is skillful if the ROC area under the curve is greater than 0.5. equation ( 3 ) R O C A = ∫ 0 1 H ( x ) d x = ∑ i = 1 M ( H i + 1 + H i ) ( F i + 1 − F i ) , Turn MathJax on where M is the classification number of the probability threshold. The ROC area, calculated as a function of the month when the model was initiated, and the lead time for the three events are shown in the left column of Fig. 5 . A perfect forecast system would have an ROC area of 1, while a system with no ability to distinguish between different events in advance would have a score of 0.5. For both the warm and cold events, the probabilistic predictions of the EPS starting from different months all have a high skill value. The ROC area was greater than 0.7 for warm events and greater than 0.75 for cold events up to a lead time of 12 months, respectively. This indicates that the EPS has a high ability to forecast extreme events in a probabilistic sense. As observed in the verifications of the ROC curve, the ROC area was lowest for predictions beginning in the spring season with a lead time of up to 3 months. The lowest ROC area was achieved by the ensemble predictions started during the autumn season when the EPS forecasts through the spring season at 6-month lead time. This seasonal variation on probabilistic skill scores of ROC area was maintained at a lead time of up to 6 months. However, the maximal difference of the ROC area between the different initial months does not exceed 0.05 for the 12-month ensemble predicted warm and cold events. In comparison with the deterministic prediction skill of the ensemble-mean, the probabilistic skill of the EPS for extreme events was not as sensitive to the initiation month. While the probabilistic skills are relative low for neutral events in comparison to extreme events, the ROC area was still above 0.55 for 12 months. This indicates that the EPS has some ability to forecast the neutral events in a probabilistic sense. However, the seasonal variation of the ROC area was more obvious for the ensemble predictions starting at different months. Especially for the first 3-month lead times, the probabilistic skill scores on the ROC area for the spring ensemble forecasts are clearly smaller than those of the ensemble forecasts that were initiated during other seasons. These seasonal differences in the probabilistic prediction skill between the three events suggest that the probabilistic predictability might be associated with the predicted SST signals, and the small predicted signals can degrade the prediction skill (e.g., Tang et al., 2005 ). 4. Potential sources of the SPB in a probabilistic sense Currently, there are two dominant hypotheses for the underlying cause of this breakdown in prediction skill. The first is that the coupling between the atmosphere and the ocean (or the coupled instability strength) is weaker during the spring than at other times of the year ( Zebiak and Cane, 1987 ). The second hypothesis is that the SST variability is weakest during the spring, and is therefore more sensitive to contamination by stochastic noise and subsequent growth of errors ( Webster and Yang, 1992 and Xue et al., 1994 ). However, in the ICM, the coupling coefficient was set to be invariant. Thus in this paper, we focused on verifying whether the weak SST variability during the spring makes the EPS more susceptible to error growth induced by stochastic processes. As mentioned in Section 2 , the EPS synthetically and systemically considers both the initial and model perturbations during the forecasting process (the forecast scheme in Section 3 is referred to as the “normal” scheme here). Therefore, to verify the effects of the two types of stochastic perturbations on ENSO probabilistic prediction skill separately, we further performed another two 16-year ensemble hindcast experiments considering either initial or model stochastic perturbations. The details of the experiments are presented in Table 2 . The initial ensemble fields of the “Initial_P” scheme were provided by the ensemble assimilation results (100 initial members), and the model perturbations were not included. The “Model_P” scheme only considered the effects of the model uncertainties during the forecast process, and its deterministic initial fields (1 initial member) were provided by the ensemble-mean assimilation results. The ROC areas for the three different events were calculated as a function of the initiation month and lead time of the two additional “Initial_P” and “Model_P” hindcast experiments. Fig. 5 shows the ROC areas in the middle and right columns, respectively. Overall, the ensemble predictions made by the EPS with initial uncertainties and model errors exhibited a less significant seasonal variation of ROC area, as did the predictions made by the EPS with only considering model error. As shown in previous results by Dewitt (2005) , when considering only the initial perturbations, the probabilistic prediction skills of the EPS for all three events were most sensitive during the initial months. The most rapid decrease in the ROC area skill occurred as the “Initial_P” hindcasts proceeded through the spring season. This suggests that the seasonal variations of the probabilistic predictability could be caused by the initial error and its growth (e.g., Chen et al., 2004 , Mu et al., 2007a , Mu et al., 2007b and Duan et al., 2009 ). Thus, this kind of initial error and its stochastic effects could be a cause of the SPB in the probabilistic sense. However, the “Model_P” prediction scheme's probabilistic skills for both the warm and cold events were much less sensitive to the initial month than those of the “Initial_P” scheme, and were even less sensitive to the initial month than those of the “normal” scheme. To explain why the additional model-error perturbations can somewhat avoid the SPB introduced by the initial uncertainties in the probabilistic sense, Fig. 6 compares the RMS errors of the ensemble-mean forecast and the averaged ensemble spread in the “Model_P” prediction scheme for the SST anomalies along the equator during the period from Nov. 1992 to Oct. 2008 as a function of the lead time. As shown in Fig. 6 , there are two high-value centers for the RMS errors of the ensemble-mean forecasts whenever the EPS was initialized in any month. These two centers represent the locations and times that were not predicted well by the model. One center was located in the eastern Pacific in May and another was centered in the central basin in December. The robust high-value center of the RMS errors in May might explain why the EPS forecasts through the spring season lead to an SPB due to the larger departure from the observation. The seasonal variation in the averaged ensemble spread represents the temporal-evolution of the additional model perturbations in the “Model_P” prediction scheme. The spreads of the forecast ensembles were very close to the RMS error, and the temporal-growth of the averaged spread, which was started from different initial months, has a very similar spatial pattern to the RMS error over the equatorial Pacific. This indicates that even the ensemble-mean forecast has a larger departure from the observation in spring season, while the associated larger increased ensemble spread can ensure similar probabilistic prediction accuracy (i.e., the hit rate) of the EPS in comparison with other months. The reasonable simulations of the time evolutions of the model uncertainties can help to improve the probabilistic prediction skills ( Zheng et al., 2006 and Zheng et al., 2009a ). These simulations indicate that the additional model-error perturbations might disorder seasonal predictability related to the SPB in the probabilistic sense. Based on the hypotheses and verifications described above, the SPB can be related to two main issues: the initial error and its stochastic effects; and the fact that the small predicted signals can make the EPS more susceptible to stochastic error growth. Here, we further adopted the signal-to-noise ratio analysis method, which was commonly employed in potential ensemble predictability studies (e.g., Tang et al., 2008 ) to examine the impacts of the two different stochastic perturbations on ENSO predictability. The signal-to-noise ratio can verify the potential predictability of the climate system by comparing the estimated the variances of the climate signals and climate noises. equation ( 4 ) R = σ ˆ S 2 σ ˆ N 2 , Turn MathJax on where R is the statistical signal-to-noise ratio of the climate element, σ̂ s 2 is the variance of the signals for the climate element, and σ̂ N 2 is the variance of the noises for the climate element. In this paper, the signal and noise variance of the SST anomalies was estimated using the ensemble-mean and the deviation about the ensemble-mean. Thus σ̂ s 2 is the inter-annual variance of the ensemble-mean forecasted SST anomalies, and σ̂ N 2 is the squared value of the averaged ensemble spread. Higher values of the signal-to-noise ratio indicate less contamination of the signal by presumably unpredictable random effects. The signal-to-noise ratio for the three different events, calculated as a function of initiation month and lead time of the three different hindcast experiments, is shown in Fig. 7 . For the “Initial_P” scheme, the signal-to-noise ratio had a strong seasonal variation and its magnitude was seen to be smaller in the first part of year. For the “normal” and “Model_P” schemes the reasonable simulations of the seasonal variations of the model uncertainties are also considered. Thus, the signal-to-noise ratio did not vary strongly between the different initial months for the warm and cold events. However, the seasonal variations of the signal-to-noise ratio for the three schemes in the neutral events were all stronger than those for extreme events. These phenomena confirm our concluded potential sources of the SPB. For this EPS, the spring (even extending into the summer) is indeed a time when the stochastic initial error effects can be expected to more easily degrade the forecast skill. The small predicted signals can also make the system noisier, thus further limiting its predictability. The evident seasonal variations of the probabilistic skills of the three prediction schemes for the neutral events also indicate that for the relatively small predicted SST anomaly signals, the EPS is more sensitive to the impacts of stochastic errors. 5. Conclusions and discussion In this paper, the seasonal variations in the EPS's predictabilities for warm, cold, and neutral events have primarily been examined in a probabilistic sense. The prediction skills for the three different events show different variation features due to the considerable differences in the evolution of the forecast error of the three different events. Results for the general ensemble prediction schemes were similar when both the initial and model uncertainties were considered, and for the ensemble forecasts when only the model uncertainties during the ensemble prediction process were considered. In these cases, the prediction barrier (i.e., the rapid decrease of the ROC area skill) only occurred for the neutral events when the hindcasts proceeded through the spring season. A significant SPB for all three events with probabilistic skills was achieved when only the initial uncertainties were considered. Further signal-to-noise ratio analysis reveals that both the initial error and the small prediction signal are among the primary factors of the spring prediction barrier of the EPS in a probabilistic sense. At the same time, reasonable stochastic model-error perturbations should not be ignored to improve the probabilistic prediction skills. These perturbations should be taken into consideration even when the seasonal variations of the forecast uncertainty was reasonably simulated to further alleviate the prediction barrier observed when only the initial errors during the ensemble forecast process are considered. However, it should be noted that the theoretical framework discussed in this study was based on a relatively simple EPS and that ENSO predictability was only studied over a relatively short period of time. There are some limitations in the current paper. All of the skills of the predictions in this paper were scored by comparing the prediction results with the observation. Therefore, the prediction uncertainties in the “Initial_P” scheme were not only caused by initial perturbations but were also caused by some model uncertainties determined by the initial perturbations (e.g., Duan and Mu, 2005 ). Thus, since the importance of the initial errors has been demonstrated in the literature ( Moore and Kleeman, 1996 , Kleeman and Moore, 1999 , Chen et al., 2004 and Mu et al., 2007a ), the impacts of the initial uncertainties of ENSO predictability generated by the ensemble data assimilation approach in our EPS should be further examined to verify whether this initial approach is model-dependent. Therefore, the ensemble prediction approach and the conclusions in this paper should be further verified in different coupled models and over longer periods. The method of generating the initial error perturbations by the ensemble data assimilation approach should also be compared to other methods of generating initial perturbations (e.g., Moore and Kleeman, 1996 and Duan and Mu, 2005 ) in future studies. Acknowledgments The authors would like to thank the anonymous reviewers for their very helpful comments and suggestions and would also like to acknowledge Dr. Rong-Hua Zhang, who provided the ICM as well as many useful comments. This research was supported by the Natural Science Foundation of China (Contract No. 40805033 ), the Chinese Academy of Science (Contract No. KZCX2-YW-202 ), the Chinese COPES project ( GYHY-200706005 ), and the National Basic Research Program of China ( 2006CB403600 ). References Corresponding author. Tel.: + 86 10 82995126; fax: + 86 10 82995123. Copyright © 2010 Elsevier B.V. All rights reserved. 
